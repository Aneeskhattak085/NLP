{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Liabraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Important libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape =  (7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "print(\"Data shape = \",data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4342\n",
      "1    3271\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10a1973d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(6,6))\n",
    "x=data_train['target'].value_counts()\n",
    "print (x)\n",
    "sns.barplot(x.index,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>location</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.332720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keyword</td>\n",
       "      <td>61</td>\n",
       "      <td>0.008013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total   Percent\n",
       "location   2533  0.332720\n",
       "keyword      61  0.008013\n",
       "target        0  0.000000\n",
       "text          0  0.000000\n",
       "id            0  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data \n",
    "total = data_train.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#get percent of missing data relevant to all data\n",
    "percent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(data_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "                          1\n",
       "  Glasgow                 1\n",
       "  Melbourne, Australia    1\n",
       "  News                    1\n",
       "  å_                      1\n",
       "                         ..\n",
       "å_: ?? ÌÑ ? : ?           1\n",
       "å_å_Los Mina Cityã¢      1\n",
       "å¡å¡Midwest Û¢Û¢        1\n",
       "åÊ(?Û¢`?Û¢å«)??         1\n",
       "åø\\_(?)_/åø               1\n",
       "Name: id, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.groupby('location')['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location and keyword columns droped successfully\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.drop(['location','keyword'], axis=1)\n",
    "print(\"location and keyword columns droped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id column droped successfully\n"
     ]
    }
   ],
   "source": [
    "data_train = data_train.drop('id', axis=1)\n",
    "print(\"id column droped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "5    #RockyFire Update => California Hwy. 20 closed...\n",
       "6    #flood #disaster Heavy rain causes flash flood...\n",
       "7    I'm on top of the hill and I can see a fire in...\n",
       "8    There's an emergency evacuation happening now ...\n",
       "9    I'm afraid that the tornado is coming to our a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"text\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus created successfully\n"
     ]
    }
   ],
   "source": [
    "corpus  = []\n",
    "pstem = PorterStemmer()\n",
    "for i in range(data_train['text'].shape[0]):\n",
    "    #Remove unwanted words\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', data_train['text'][i])\n",
    "    #Transform words to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    #Remove stopwords then Stemming it\n",
    "    tweet = [pstem.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    #Append cleaned tweet to corpus\n",
    "    corpus.append(tweet)\n",
    "    \n",
    "print(\"Corpus created successfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            deed reason earthquak may allah forgiv us\n",
      "1                 forest fire near la rong sask canada\n",
      "2    resid ask shelter place notifi offic evacu she...\n",
      "3          peopl receiv wildfir evacu order california\n",
      "4    got sent photo rubi alaska smoke wildfir pour ...\n",
      "5    rockyfir updat california hwi close direct due...\n",
      "6    flood disast heavi rain caus flash flood stree...\n",
      "7                               top hill see fire wood\n",
      "8               emerg evacu happen build across street\n",
      "9                             afraid tornado come area\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(corpus)[0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text after cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>rockyfir updat california hwi close direct due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>flood disast heavi rain caus flash flood stree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>top hill see fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>emerg evacu happen build across street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>afraid tornado come area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  I'm on top of the hill and I can see a fire in...   \n",
       "8  There's an emergency evacuation happening now ...   \n",
       "9  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "                                 text after cleaning  \n",
       "0          deed reason earthquak may allah forgiv us  \n",
       "1               forest fire near la rong sask canada  \n",
       "2  resid ask shelter place notifi offic evacu she...  \n",
       "3        peopl receiv wildfir evacu order california  \n",
       "4  got sent photo rubi alaska smoke wildfir pour ...  \n",
       "5  rockyfir updat california hwi close direct due...  \n",
       "6  flood disast heavi rain caus flash flood stree...  \n",
       "7                             top hill see fire wood  \n",
       "8             emerg evacu happen build across street  \n",
       "9                           afraid tornado come area  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTexData = data_train[\"text\"].head(10)\n",
    "cleanTexData = pd.DataFrame(corpus, columns=['text after cleaning']).head(10)\n",
    "\n",
    "frames = [rawTexData, cleanTexData]\n",
    "result = pd.concat(frames, axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>co</td>\n",
       "      <td>4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http</td>\n",
       "      <td>4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fire</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>amp</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>get</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bomb</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>new</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>via</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>u</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word Frequent\n",
       "co             4746\n",
       "http           4721\n",
       "like            411\n",
       "fire            363\n",
       "amp             344\n",
       "get             311\n",
       "bomb            239\n",
       "new             228\n",
       "via             220\n",
       "u               216"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create our dictionary \n",
    "uniqueWordFrequents = {}\n",
    "for tweet in corpus:\n",
    "    for word in tweet.split():\n",
    "        if(word in uniqueWordFrequents.keys()):\n",
    "            uniqueWordFrequents[word] += 1\n",
    "        else:\n",
    "            uniqueWordFrequents[word] = 1\n",
    "            \n",
    "#Convert dictionary to dataFrame\n",
    "uniqueWordFrequents = pd.DataFrame.from_dict(uniqueWordFrequents,orient='index',columns=['Word Frequent'])\n",
    "uniqueWordFrequents.sort_values(by=['Word Frequent'], inplace=True, ascending=False)\n",
    "uniqueWordFrequents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4746, 4721,  411,  363,  344,  311,  239,  228,  220,  216,  213,\n",
       "        210,  209,  201,  183,  181,  180,  178,  175,  169,  166,  164,\n",
       "        162,  156,  155,  153,  151,  145,  144,  143,  137,  133,  132,\n",
       "        131,  130,  129,  128,  125,  124,  123,  122,  121,  120,  119,\n",
       "        118,  117,  116,  114,  111,  110,  109,  108,  106,  105,  104,\n",
       "        103,  102,  101,  100,   99,   98,   97,   96,   95,   94,   93,\n",
       "         91,   90,   89,   88,   87,   86,   84,   83,   82,   79,   78,\n",
       "         77,   76,   75,   74,   73,   72,   71,   70,   69,   68,   67,\n",
       "         66,   65,   64,   63,   62,   61,   60,   59,   58,   57,   56,\n",
       "         55,   54,   53,   52,   51,   50,   49,   48,   47,   46,   45,\n",
       "         44,   43,   42,   41,   40,   39,   38,   37,   36,   35,   34,\n",
       "         33,   32,   31,   30,   29,   28,   27,   26,   25,   24,   23,\n",
       "         22,   21,   20,   19,   18,   17,   16,   15,   14,   13,   12,\n",
       "         11,   10,    9,    8,    7,    6,    5,    4,    3,    2,    1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWordFrequents['Word Frequent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>co</td>\n",
       "      <td>4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>http</td>\n",
       "      <td>4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fire</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>amp</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cnn</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gem</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>captur</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>arriv</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>carri</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word Frequent\n",
       "co               4746\n",
       "http             4721\n",
       "like              411\n",
       "fire              363\n",
       "amp               344\n",
       "...               ...\n",
       "cnn                20\n",
       "gem                20\n",
       "captur             20\n",
       "arriv              20\n",
       "carri              20\n",
       "\n",
       "[787 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWordFrequents = uniqueWordFrequents[uniqueWordFrequents['Word Frequent'] >= 20]\n",
    "print(uniqueWordFrequents.shape)\n",
    "uniqueWordFrequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "counVec = CountVectorizer(max_features = uniqueWordFrequents.shape[0])\n",
    "bagOfWords = counVec.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape =  (7613, 787)\n",
      "y shape =  (7613,)\n",
      "data splitting successfully\n"
     ]
    }
   ],
   "source": [
    "X = bagOfWords\n",
    "y = data_train['target']\n",
    "print(\"X shape = \",X.shape)\n",
    "print(\"y shape = \",y.shape)\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.20, random_state=55, shuffle =True)\n",
    "print('data splitting successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision Tree Classifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "decisionTreeModel = DecisionTreeClassifier(criterion= 'entropy',\n",
    "                                           max_depth = None, \n",
    "                                           splitter='best', \n",
    "                                           random_state=55)\n",
    "\n",
    "decisionTreeModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"decision Tree Classifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient Boosting Classifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "gradientBoostingModel = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                                   learning_rate = 0.01,\n",
    "                                                   n_estimators = 100,\n",
    "                                                   max_depth = 30,\n",
    "                                                   random_state=55)\n",
    "\n",
    "gradientBoostingModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"gradient Boosting Classifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "KNeighborsModel = KNeighborsClassifier(n_neighbors = 7,\n",
    "                                       weights = 'distance',\n",
    "                                      algorithm = 'brute')\n",
    "\n",
    "KNeighborsModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"KNeighbors Classifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Classifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression = LogisticRegression(penalty='l2', \n",
    "                                        solver='saga', \n",
    "                                        random_state = 55)  \n",
    "\n",
    "LogisticRegression.fit(X_train,y_train)\n",
    "\n",
    "print(\"LogisticRegression Classifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier Classifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDClassifier = SGDClassifier(loss = 'hinge', \n",
    "                              penalty = 'l1',\n",
    "                              learning_rate = 'optimal',\n",
    "                              random_state = 55, \n",
    "                              max_iter=100)\n",
    "\n",
    "SGDClassifier.fit(X_train,y_train)\n",
    "\n",
    "print(\"SGDClassifier Classifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVClassifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "SVClassifier = SVC(kernel= 'linear',\n",
    "                   degree=3,\n",
    "                   max_iter=10000,\n",
    "                   C=2, \n",
    "                   random_state = 55)\n",
    "\n",
    "SVClassifier.fit(X_train,y_train)\n",
    "\n",
    "print(\"SVClassifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernoulliNB model run successfully\n"
     ]
    }
   ],
   "source": [
    "bernoulliNBModel = BernoulliNB(alpha=0.1)\n",
    "bernoulliNBModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"bernoulliNB model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussianNB model run successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussianNBModel = GaussianNB()\n",
    "gaussianNBModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"gaussianNB model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB model run successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialNBModel = MultinomialNB(alpha=0.1)\n",
    "multinomialNBModel.fit(X_train,y_train)\n",
    "\n",
    "print(\"multinomialNB model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "votingClassifier model run successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "modelsNames = [('LogisticRegression',LogisticRegression),\n",
    "               ('SGDClassifier',SGDClassifier),\n",
    "               ('SVClassifier',SVClassifier),\n",
    "               ('bernoulliNBModel',bernoulliNBModel),\n",
    "               ('multinomialNBModel',multinomialNBModel)]\n",
    "\n",
    "votingClassifier = VotingClassifier(voting = 'hard',estimators= modelsNames)\n",
    "votingClassifier.fit(X_train,y_train)\n",
    "print(\"votingClassifier model run successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7dc88bed2881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                max_features = 'sqrt')\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier  Train Score is   :  0.9761904761904762\n",
      "DecisionTreeClassifier  Test Score is    :  0.7419566644780039\n",
      "DecisionTreeClassifier  F1 Score is      :  0.6743993371996686\n",
      "--------------------------------------------------------------------------\n",
      "GradientBoostingClassifier  Train Score is   :  0.8594417077175698\n",
      "GradientBoostingClassifier  Test Score is    :  0.7511490479317138\n",
      "GradientBoostingClassifier  F1 Score is      :  0.6331074540174251\n",
      "--------------------------------------------------------------------------\n",
      "KNeighborsClassifier  Train Score is   :  0.9761904761904762\n",
      "KNeighborsClassifier  Test Score is    :  0.7406434668417596\n",
      "KNeighborsClassifier  F1 Score is      :  0.5872518286311389\n",
      "--------------------------------------------------------------------------\n",
      "LogisticRegression  Train Score is   :  0.8502463054187193\n",
      "LogisticRegression  Test Score is    :  0.7826657912015759\n",
      "LogisticRegression  F1 Score is      :  0.7230125523012553\n",
      "--------------------------------------------------------------------------\n",
      "SVC  Train Score is   :  0.8574712643678161\n",
      "SVC  Test Score is    :  0.7741300065659882\n",
      "SVC  F1 Score is      :  0.7180327868852457\n",
      "--------------------------------------------------------------------------\n",
      "BernoulliNB  Train Score is   :  0.8091954022988506\n",
      "BernoulliNB  Test Score is    :  0.7774130006565988\n",
      "BernoulliNB  F1 Score is      :  0.7129551227773073\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#evaluation Details\n",
    "models = [decisionTreeModel, gradientBoostingModel, KNeighborsModel, LogisticRegression, \n",
    "         SVClassifier, bernoulliNBModel]\n",
    "\n",
    "for model in models:\n",
    "    print(type(model).__name__,' Train Score is   : ' ,model.score(X_train, y_train))\n",
    "    print(type(model).__name__,' Test Score is    : ' ,model.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(type(model).__name__,' F1 Score is      : ' ,f1_score(y_test,y_pred))\n",
    "    print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
